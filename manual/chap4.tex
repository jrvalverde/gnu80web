\chapter{\sf Modifications to {\tt gnu80}}
\section{\sf Warning}
It must be said at the outset that any decision to make
significant changes to {\tt gnu80} should not be taken lightly.
In common with all the GAUSSIAN series of programs, {\tt gnu80}
is {\bf fragile}; it  is:
\begin{itemize}
\item Fragile in {\em design}; the whole system has grown up
empirically and has the  ``bottom up'' structure
of Baroque complexity associated with such developments.
\item Fragile in {\em data communication}; changes in the code
may have unpredictable effects in remote parts of the system.
\item Fragile in  {\em ``data structures'' }; this point
is treated in detail below in the discussion of {\tt TREAD} and
{\tt TWRITE}.
\item Fragile in {\em detailed coding}; there is no consistent
nomenclature convention and much of the code is not FORTRAN 77
and is FORTRAN 8x deprecated.
\end{itemize}

However, it does work and work very well. It can be considerably
improved from the point of view of maintenance and development be
{\em systematically} removing the worst of the fragility; in a word
to make the system more {\em robust}.

In this  respect the most rewarding excercise would be to make the
system more modular; involving:
\begin{itemize}
\item The rationalisation of the inter-link interfaces, the
rationalisation of the COMMON blocks in names, lengths and
internal structure and the conversion of the file numbers in which
the COMMON blocks are stored (and their lengths) into Global
objects.
\item Systematic elimination of the riot of EQUIVALENCE statements.
\end{itemize}
These changes (supported by improvements in documentation)
\footnote{
Here, as elsewhere, it is important to distinguish between
{\em program documentation} and mere {\em operating instructions}
}
would make the links into large-scale ``Objects''
(in modern terminology) which would recognise and act on the 
COMMON block messages.

However, from a quantum chemistry point of view, these enhancements
are non-productive work and most efforts are likely to be concentrated
on {\em functional} enhancements to the system.
\section{\sf Preview}
There are two very broad categories of change which may be
made to {\tt gnu80}:
\begin{itemize}
\item Improvement or replacement of existing functionality (e.g.
speeding up the code or implementing new integral evaluation techniques
or diagonalisation methods).
\item Introduction of completely new facilities (e.g. the addition
of a Random Phase Approximation link)
\end{itemize}
The second of these requires everything that the first requires
{\em plus} changes to the parser tables and route generator
in order that the
new command may be recognised and an appropriate route generated.

For the time being, attention is concentrated on the former enhancement.
Within this framework there are again two broad areas where changes might
be made:
\begin{itemize}
\item The calculation of molecular integrals over the basis functions;
one-electron integrals or electron-repulsion integrals and the use of
these new integrals with the existing quantum-mechanical models.
\item The use of existing integral generation facilities to implement
additional quantum-mechanical techniques.
\end{itemize}
In fact, the latter is easier to implement for obvious
reasons; all that is neede is the location of the one-electron
integrals (the COMMON block) and the file containing the repulsion integrals.
In the former case the data structures describing the atoms in the molecule
and the orbital basis etc. must be located {\em and the detailed
structure of the information known}.

Before any particular case can be discussed, it is necessary to
have an ``overview'' of the salient parts of {\tt gnu80}
(and, by implication GAUSSISAN) organisation.
\section{\sf Data Communication in {\tt gnu80}}
The numerical work invlved in {\em ab initio} quantum chemical
calculations fall naturally into a series of independent tasks.
The overall structure of {\tt gnu80} reflects this underlying
modularity. The large size of {\tt gnu80} means that it must
sometimes be overlaid and, more important, the demands made
for computrer resources (time and file store) are such that the
system should be re-startable after a machine event.

This raises the question of data communication between the modules of
{\tt gnu80}. The communication must be done via non-volatile (disk) files
which have to contain the essential data structures input to the system
or generated by the system which are essential for later modules.

Broadly speaking the data structures are of two types:
\begin{enumerate}
\item Electron-repulsion integrals
\item Other, more heterogeneous, data input or generated by the system;
one-electron integrals, orbital and symmetry specifcations etc. etc.
\end{enumerate}
The latter sets of data are grouped together in {\tt gnu80} as named
COMMON blocks, copies of which are output as they are updated or
as a link is changed so that the contents of the COMMON blocks
may be restored at a later stage in the run.

This method of data communication makes use of one of the
peculiarities of the 
FORTRAN language which enables a heterogeneous set of data to be treated as a 
single unit, providing a crude kind of ``DATA STRUCTURE'' in
FORTRAN.

The COMMON facility of FORTRAN declares a specific set of variables
to be {\em global}; to be available to all program segments in which the
COMMON declaration
\begin{center}
{\tt COMMON /CNAME/ list}
\end{center}
is made (where {\tt CNAME} is the literal name of the COMMON block and
{\tt list} is a list of variables of arbitrary type).
A side-effect of this facility is that the items in the {\tt list}
are forced to be {\em contiguous} in storage. That is the whole
COMMON block can be addressed by (e.g.) the address of the first
member of {\tt list}. Now, recall that FORTRAN passes all parameters
to SUBROUTINEs ``by address'' . Thus, knowing the
name of the first member of {\tt list} and the {\em length} of {\tt list}
(in some convenient units like the length of an integer or a double
precision real), we may pass this information through an inter-segment
interface and {\em treat it as a unit} since FORTRAN forgets
everything except the address in such circumstances. Again, in modern
terminology, the arguments of SUBROUTINES in FORTRAN are
``Overloaded'' .

In particular, we may write the whole of {\tt list} and read it back
{\em as a unit} in one FORTRAN statement; providing an efficient,
if crude, method
of inter-link data communication.
An example will make this clear, particularly to the non-FORTRAN
programmer:
\newpage
\begin{verbatim}
      DOUBLE PRECISION A
      INTEGER FILE, FLEN, I, J, K, L, ID
      COMMON /DUMMY/ I, J, A(200), K, L(50), ID
      DATA FILE, FLEN/10,227/
      .
      .
      .
      CALL WRITE(FILE,FLEN,I)
      .
      .
      END
      SUBROUTINE WRITE(UNIT,LENGTH,START)
      INTEGER UNIT, LENGTH
      DOUBLE PRECISION START(1)
      INTEGER I
      WRITE(UNIT) (START(I),I=1,LENGTH)
      RETURN
      END
\end{verbatim}

The FORTRAN channel number of the file is {\tt FILE} (i.e. 10)
and its length is {\tt FLEN} (i.e. 227) assuming that
one double precision real is twice as long as an integer.
Notice that {\tt WRITE} is called with an {\tt INTEGER} argument ({\tt I})
whereas the type of the third argument of {\tt WRITE} is 
{\tt DOUBLE PRECISION}, FORTRAN allows this but it will often be
flagged as an error if one calls a routine with arguments of different
type in the same segment.

This is the method used in {\tt gnu80}, the routines {\tt TWRITE} and
{\tt TREAD} are the ones which perform these tasks; manual pages are 
given below.
\newpage
\begin{description}
\item[NAME] TWRITE \\
Standard file output routine
\item[SYNOPSIS] \ \\
{\tt
   subroutine TWRITE(FILE,X,M,N,MM,NN,K) \\
   double precision X(1) \\
   integer FILE, M, N, MM, NN, K \\
}
\item[DESCRIPTION] \ \\
TWRITE writes data to the {\tt gnu80} internal file number {\tt FILE}
from the double precision array {\tt X}. In the calling segment
X must be {\tt DIMENSION}ed {\tt MM} by {\tt NN}. The data written
is taken from this array as far as {\tt M} by {\tt N} consistent
with FORTRAN matrix storage rules. {\tt K} indicates whether or
not the matrix has been stored in a compressed mode (for symmetric
matrices) i.e. contains only M(M+1)/2 elements, not M**2.
The routine is called to write actual matrices to files {\em and}
to write COMMON blocks in which case usually {\tt N=NN=1}
and {\tt M=MM=} length of file (in units of double precision reals,
padded out if necessary)
\item[ARGUMENTS:] \ \\
\begin{description}
\item[FILE]  The {\tt gnu80} internal file number
\item[X] Array containing the data to be written.
\item[M] Actual number of rows in the matrix X.
\item[N] Actual number of columns in the matrix X.
\item[MM] Number of rows in the DIMENSION statement of calling program.
\item[NN] Number of columns in the DIMENSION statement of calling program.
\item[K] {\tt K = 0} means that all the matrix is write, {\tt K = 1}
means only ``half'' was write.
\end{description}
\item[SEE ALSO] \ \\
TREAD, TQUERY, NTRAN, FILEIO
\item[DIAGNOSTICS]
None; but NTRAN tracks errors
\end{description}
\newpage
\begin{description}
\item[NAME] TREAD \\
Standard file input routine
\item[SYNOPSIS] \ \\
{\tt
   subroutine TREAD(FILE,X,M,N,MM,NN,K) \\
   double precision X(1) \\
   integer FILE, M, N, MM, NN, K \\
}
\item[DESCRIPTION] \ \\
TREAD reads data from the {\tt gnu80} internal file number {\tt FILE}
into the double precision array {\tt X}. In the calling segment
X must be {\tt DIMENSION}ed {\tt MM} by {\tt NN}. The data read
is stored in this array as far as {\tt M} by {\tt N} consistent
with FORTRAN matrix storage rules. {\tt K} indicates whether or
not the matrix has been stored in a compressed mode (for symmetric
matrices) i.e. contains only M(M+1)/2 elements, not M**2.
The routine is called to read actual matrices from files {\em and}
to read COMMON blocks in which case usually {\tt N=NN=1}
and {\tt M=MM=} length of file (in units of double precision reals,
padded out if necessary)
\item[ARGUMENTS:] \ \\
\begin{description}
\item[FILE]  The {\tt gnu80} internal file number
\item[X] Array to receive the data read.
\item[M] Actual number of rows in read matrix.
\item[N] Actual number of columns in read matrix.
\item[MM] Number of rows in the DIMENSION statement of calling program.
\item[NN] Number of columns in the DIMENSION statement of calling program.
\item[K] {\tt K = 0} means that all the matrix is read, {\tt K = 1}
means only ``half'' was read.
\end{description}
\item[SEE ALSO] \ \\
TWRITE, TQUERY, NTRAN, FILEIO
\item[DIAGNOSTICS]
None; but NTRAN tracks errors
\end{description}
\newpage
The advantages of simplicity using this method are obvious but it
has contributed to the fragility of {\tt gnu80} by requiring both
the name of the first member of the COMMON block {\em and its length}.
If, for example, one makes an addition to a COMMON block which is
required to be communicated to other links then the CALL to
{\tt TWRITE} and {\tt TREAD} must be changed to allow for the
new length. Unfortunately, many of these lengths are effectively
``hard-wired'' into {\tt gnu80} as absolute constants. They must
be made Global variables if changes are to be made securely.
\section{\sf {\tt gnu80} Read/Write Files}
Here is a list of the {\tt gnu80} internal file
numbers currently in use and their contents.
\begin{description}
\item[501] COMMON /GEN/
\item[502] Title and Atomic Orbital labels
\item[503] Error Function interpolation table
\item[504] Coordinate portion of blank COMMON
\item[505] AO scaling factors
\item[506] COMMON/B/; Basis set information 
\item[507] COMMON /ZMAT/, the Z-matrix
\item[508] COMMON /IBF/ integral buffer format
\item[509] incomplete integral buffer
\item[510] COMMON /FPINFO/ Fletcher-Powell optimization program data
\item[511] COMMON /GRDNT/ energy, first and second derivatives over NVAR
\item[512] pseudo-potential information
\item[513] COMMON /DIBF/ integral derivative buffer format
\item[514] Overlap matrix
\item[515] Core-hamiltonian
\item[516] Kinetic energy integrals
\item[517] Fermi contact integrals
\item[518] x-dipole integrals
\item[519] y-dipole integrals
\item[520] z-dipole integrals
\item[521] Cartesian first and second derivatives of the energy
\item[522] eigenvalues, $\alpha$ and if necessary, $\beta$
\item[523] symmetry assignments
\item[524] MO coefficients, real $\alpha$
\item[525] MO coefficients, imaginary $\alpha$
\item[526] MO coefficients, real $\beta$
\item[527] MO coefficients, imaginary $\beta$
\item[528] density matrix, real $\alpha$
\item[529] density matrix, imaginary $\alpha$
\item[530] density matrix, real $\beta$
\item[531] density matrix, imaginary $\beta$
\item[532] density matrix, real total
\item[533] density matrix, imaginary total
\item[534] density matrix, real spin
\item[535] density matrix, imaginary spin
\item[536] Fock matrix, real $\alpha$
\item[537] Fock matrix, imaginary $\alpha$
\item[538] Fock matrix, real $\beta$
\item[539] Fock matrix, imaginary $\beta$
\item[540] molecular $\alpha$-$\beta$ overlap (u), real
\item[541] molecular $\alpha$-$\beta$ overlap (u), imaginary
\item[542] pseudo-potential information
\item[543] pseudo-potential information
\item[544] pseudo-potential information
\item[545] COMMON /ORB/ - window information
\item[546] bucket entry points
\item[547] eigenvalues (double precision with window: always $\alpha$
and $\beta$, even in RHF case)
\item[548] MO coefficients (double precision with window, $\alpha$ and
if necessary, $\beta$)
\item[549] molecular orbital $\alpha$-$\beta$ overlap, double precision with
window
\item[550] holds virgin copy of COMMON /B/ during GBASIS optimizations.
\item[551] symmetry operation info (permutations, transformation
matrices, etc.)
\item[552] character strings containing the stoichiometric formula
and framework group designation.
\item[553] temporary storage of COMMON /GEN/ during {\bf FP} optimizations.
\item[554] alternate starting MO coefficients, from L918
L503, real $\alpha$.
\item[555] alternate starting MO coefficients, from L918
L503, imaginary $\alpha$.
\item[556] alternate starting MO coefficients, from L918
L503, real $\beta$.
\item[557] alternate starting MO coefficients, from L918
to L503, imaginary $\beta$.
\item[558] computed harmonic frequencies, in wavenumbers.
\item[559] COMMON /MAP/.
\item[562] symmetry operations for orbital symmetry assignments.
\item[563] integer symmetry assignments ($\alpha$).
\item[564] integer symmetry assignments ($\beta$).
\item[565] lists of symmetry equivalent shells and basis functions
\item[566] symmetry partitions for l506
\item[567] GVB pair information
\item[568] occupation numbers and J and K coefficients (L506)
\item[569] label COMMON for L506
\item[570] COMMON /ZSUBST/
\item[571] energy weighted density matrix.
\item[572] coordinate array with dummies intact.
\item[573] not used 
\item[574] COMMON /MSINFO/  Murtaugh-Sargent program data
\item[575] COMMON /OPTGRD/  gradient optimization program data
\item[576] COMMON /TESTS/ control constants in L105
\item[577] non default atomic charges
\item[992] COMMON /NTR/
\item[993] COMMON /INFO/
\item[994] COMMON /PHYCON/
\item[995] COMMON /MUNITS/
\item[996] COMMON /IOP/
\item[997] COMMON /MOL/
\item[998] COMMON /ILSW/
\item[999] Overlay data
\end{description}
\newpage
\section{\sf Basic I/O Routines}
There are two types of disk I/O performed by {\tt gnu80}:
\begin{enumerate}
\item Inter-link data communication and scratch I/O
\item Electron-repulsion integral storage and retrieval
\end{enumerate}
The first of these use {\bf TREAD} and {\bf TWRITE} as we have seen above.
These routines call {\bf FILEIO} which itself calls the most
basic routine {\bf NTRAN}. The repulsion integral I/O is performed by
calls to the various entry points of a general integral I/O
routine {\bf INTEGI} which calls {\bf NTRAN}.

Manual pages for {\bf FILEIO} and {\bf NTRAN} are given below.
\newpage
\begin{description}
\item[NAME] FILEIO \\
Random access Input/Output
\item[SYNOPSIS] \ \\
{\tt
   subroutine FILEIO(IOPER, IFILNO, LEN, Q, IPOS) \\
   double precision Q(1) \\
   integer IOPER, IFILNO, LEN, IPOS \\
}
\item[DESCRIPTION] \ \\
{\bf FILEIO} performs all the  functions  dealing  with the logically
{\em random-access} I/O of {\tt gnu80}.
 
Although {\bf FILEIO} may appear to maintain a large  number  of
files  (up  to 200), all of this data is actually stored into a
{\em single}  disk file in the usual FORTRAN sense.  
This (FORTRAN random access) file is divided  up by {\bf FILEIO}
and  portions of it are allocated to each of the logical files
(buckets and read-write files). Thus ``files '' in
{\bf FILEIO} terminology are not the same as ``files'' 
in standard FORTRAN terminology. It is therefore necessary to
use one or the other consistently in a program. {\tt gnu80} uses
``files'' always to mean {\bf FILEIO}-compatible
files. Thus data {\em must} always be read or written by {\bf FILEIO}
and {\em not} by standard FORTRAN READ or WRITE statements.
Of course, {\bf FILEIO} itself uses standard FORTRAN statements
to do the actual I/O!

The two types of file ``buckets'' and ``read-write
files'' only differ conceptually not essentially; roughly
speaking, read-write files are inter-link communication
and buckets are scratch space (particularly during integral
transformations).

For each file (bucket or read-write  file),  {\bf FILEIO}  
maintains  both  read  and  write pointers.  A write operation on a
file, for instance, starts at the position of the write pointer
for  that  file.   For each value written, the write pointer is
incremented.  The read pointer behaves the same way on read operations.
\item[ARGUMENTS:] \ \\
\begin{description}
\item[IOPER]   type of I/O operation to perform:
\begin{description} 
\item[0] define file   {\tt IFILNO}  to have length  {\tt LEN}   
\item[+1]  synchronous write operation. Control   returns  to  the
calling routine when the write is completed.
(this operation defines a file with length {\tt LEN} if the file
was not previously defined). Note that in {\tt gnu80} {\em portable}
FORTRAN I/O is used so that {\em all } I/O is synchronous notwithstanding
information to the contrary.
\item[+2]  synchronous read operation.
\item[4]  define subfile.
\item[5]  delete the file indicated by {\tt IFILNO}.
\item[6]  delete all routine-volatile files (those  with  numbers
larger that 2999).
\item[7]  delete all the link-volatile files.  This should  not
be done by a user directly, but rather let {\tt NEXTOV} do this
for you when overlaying.
\item[8]  delete all overlay-volatile files.  Once again, don't do
this unless you're sure you know what you're doing.
\item[9]  {\bf FILEIO} open.  This is done in chain at the beginning of
the program, and should not be used elsewhere.
\item[10]  {\bf FILEIO} close.  This is done automatically by {\tt NEXTOV} on
its way out, and should not be used elsewhere.
\item[11]  this returns the length of the specified file (in {\tt LEN}).
if the file is undefined, then 0 is returned.  Thus,
you can check for the existence of a file before trying
to read from it.
\item[12]  {\bf FILEIO} initialization. This is done by {\tt MAIN} at the
beginning of the run, and should not be done elsewhere.
\end{description}
\item[IFILNO] The absolute value of {\tt IFILNO} is the number  of  the  file
which is to be read, written, defined, or deleted.  Any
non-zero value in permitted, but the following  
conventions are to be observed in {\tt gnu80}:
\begin{description} 
\item[1-499]  permanent buckets.
\item[500-999] permanent read-write files.
\item[1000-1499]  overlay volatile buckets.  These are  
deleted automatically before each new overlay.
\item[1500-1999]  overlay volatile read-write files.
\item[2000-2499]  link volatile buckets.  These  are  
automatically deleted before each new link.
\item[2500-2999]  link volatile read-write files.
\item[3000-3499]  routine volatile buckets.  These are  
deleted when {\bf FILEIO} is called with {\tt IOPER=6},
and also before each new link.
\item[3500-3999]  routine volatile read-write files.
\end{description} 
For read or write operations, supplying the {\em negative}
of  the  file number causes the read or write 
pointer to be rewound (reset to the base of the file) 
before  the operation. Note that this is done before the
argument {\tt IPOS} is processed.  For file deletion or file
definition operations, the sign of the file number is
ignored.
\item[LEN]   This quantity is the number of double precision values
(quadruples of bytes, usually)  to be transferred in a read or a write 
operation, or the number of these values to be allocated
in a define file operation.
\item[Q] a double precision array for the data read or written.
\item[IPOS] Used to help specify the position in the   file
at  which  an I/O operation will commence. The value of
the read or write pointer is incremented by {\tt IPOS} before
the read or write operation is performed. The possible
rewind of the pointer (as specified by  the  {\em sign}  of
{\tt IFILNO}) is done before {\tt IPOS} is considered.  Thus, a 
{\em positive} file number means that {\tt IPOS} specifies  the  new
position relative to the current position; a {\em negative}
{\tt IFILNO} means {\tt IPOS} specifies the new  position relative
to the begining of the file.
\end{description}
\item[SEE ALSO] \ \\
{\bf NTRAN, TREAD, TWRITE}
\item[DIAGNOSTICS] \ \\
None directly, but {\bf NTRAN} provides some.
\end{description}
\newpage
\begin{description}
\item[NAME] NTRAN \\
Lowest level I/O routine.
\item[SYNOPSIS] \ \\
{\tt
   subroutine NTRAN(UNIT, OP, NWRDS, X, L) \\
   double precision X(1) \\
   integer UNIT, OP, NWRDS, L \\
}
\item[DESCRIPTION] \ \\
This routine is developed to handle the I/O requests of {\bf FILEIO} and
to perform all asynchronous I/O. (two electron storage).  It provides
{\tt gnu80} with a {\em word addressable} disc I/O capability.  It is called
by {\bf FILEIO} and the routines {\bf IREAD, IWRITE, IWIND} etc. 
which are ENTRY points to {\bf INTEGI}

\begin{center}
\fbox{
\parbox{3.5in}{
\bf NTRAN can nominally handle synchronous and asynchronous I/O requests.
In the {\tt gnu80} implementation all I/O is portable FORTRAN 77 and so
there is no asynchronous I/O but the code has been left in (as
comments) in case this facility is ever supported by future FORTRANs.
}
}
\end{center}

Synchronous I/O is random access (on 4 byte word level),
{\bf NTRAN} is designed to allow the FORTRAN programmer to store and
fetch arbitrary data from disc.  Arbitrary means that any 
number of 4 byte words may be transferred to or from any location
on a disc file.
Asynchronous I/O is basically sequential, and more restricted
than synchronous I/O, in the sense that only an {\em integer} number
of records can be written or read. This implies that 
the same number of words must be read back as were written out on that
record previously.
All operations or options are performed only on the specified
unit.
The synchronous I/O is performed with the use of a direct access unit.
At the moment this is fixed (through a {\tt DEFINE FILE}
statement). Because of this {\bf NTRAN} can only handle one direct access
unit ({\tt DEFINE}d to FORTRAN unit  18), but the code could be extended to
handle other direct access without much effort.  Currently {\tt gnu80}
only uses one asynchronous unit (3) but {\bf NTRAN} is coded to handle 2
more (just define them through an appropriate {\bf NTRAN} call).

Note that the code in {\bf NTRAN} traps most of the common errors
{\em before} the FORTRAN I/O does, so that, for example, attempts to
read an unwritten record is trapped and an error message given. This
policy has only one possible bad side-effect; the {\em length} of
the total file is specified by the program as {\tt LEN18*RECL}
where {\tt RECL} is the record length specified in the {\tt OPEN}
statement for unit 18 (see Chapter \ref{install}). This number need
not have any relationship to the {\em actual}  disk space available
on a particular system. So it is possible, by setting {\tt LEN18}
too small, to get a message that there is no file space left when
there is physical space available. The solution is obvious; set {\tt LEN18}
as a very large integer and risk a system-generated storage crisis or
actually {\em calculate} {\tt LEN18} for your filestore.

Usage notes:
\begin{enumerate}
\item  {\tt UNIT} must always be equal to one of the 
logical unit numbers stored
in the array {\tt UNITS}, even for calls which are not device specific.
\item  Don't rewind before a reposition. If necessary, 
{\bf NTRAN} will do this
automatically. To reposition {\bf NTRAN} will either: \\
Read records until the specified position is reached, and if
necessary write records to extend the file. \\
Backspace the unit until the specified location is reached \\
Rewind the unit and skip records to the specified location.
\item Only use {\tt OP}=23 (wait) if you want to use the  data read or
redefine the array used in a write operation. All other
waits are performed automatically if needed. Use the negative
form of the op parameter if you want to simulate synchro-
nous I/O on an otherwise asynchronous unit.
\item The correct sequence of operation is (synchronous) \\
a) define unit (26) \\
b) reopen unit if it is an old file (21) \\
c) reposition unit (6) \\
d) read/write (2,1) \\
e) go to c \\
asynchronous: \\
a) define unit (27) \\
b) rewind unit (10) \\
c) read or write \\
d) a rewind (10)  should be issued
between read and write operations
\end{enumerate}
\item[ARGUMENTS:] \ \\
\begin{description}
\item[UNIT]  the fortran logical unit number of the file to be
accessed.  {\tt UNIT} maps onto a local unit number
via the array {\tt UNITS}.  All calls to {\bf NTRAN}
require a valid unit.  Note that the value of {\tt IUNIT}
is used as a local event flag number to signal
I/O completion of asynchronous I/O.
\item[OP] specifies the operation to carry out. A {\em negative}
value indicates that {\bf NTRAN} is not to return control
to the calling program until the requested I/O
operation is complete. (only for 1 and 2)
\begin{description}
\item[+/- 1] write
\item[+/- 2] read
\item[6] reposition
\item[10] rewind
\item[21] reopen old unit, {\tt NWRDS} = number of records in old file.
\item[22] close unit (only for synchronous I/O)
\item[23] wait
\item[26] define synchronous  unit (always done first)
\item[27] define asynchronous unit (always done first)
\item[29] print switch, {\tt NWRDS}=0 means no printing, 
{\tt NWRDS}$\not=0$ means print.
\end{description}
\item[NWRDS] the number of words involved in the operation.
A radix (number of 8 bit bytes per user datum)
of 4 is assumed, thus nwrds specifies the number of
longwords to transfer.
\item[X] data to be transferred.
\item[L] status word: \\
-1 indicates operation in progress \\
-3 indicates end of file was encountered during 
synchronous read \\
-2 indicates error \\
$>0$ indicates successful completion of the request,
{\tt L} containing the number of words transferred. \\
Note that as currently coded {\bf NTRAN} will abort the job
if an error occurs, therefore L=-3 should not occur.
\end{description}
\item[SEE ALSO] \ \\
{\bf FILEIO}
\item[DIAGNOSTICS] \ \\
Provides error trapping {\em before} the FORTRAN diagnostics.
\end{description}
\newpage
\section{\sf Two-electron Integral Storage}
\label{stor2e}
\subsection{\sf Introduction}
The efficient storage and retrieval of the huge numbers of
electron-repulsion integrals generated during any {\em ab initio}
caculation is a major design problem in quantum chemical calculations.
Fortunately, the access of the basis-function integrals is essentially
{\em sequential}.
The number of basis-function repulsion integrals is proportional
to the fourth power of the number of basis functions and the
time required to compute any one of them depends on the {\em type}
of the basis function and the number of primitive Gaussian functions
which make up the four basis functions involved in the integral;
if each basis function is of the same degree of contraction then the
time taken to compute an integral depends on the fourth power of
this degree of contraction.

During the generation of the electron repulsion integrals they
are placed into a {\em Buffer} which is written out to
mass storage when it is full. The process continues until
a complete (sequential) file of all the integrals has been
generated. The way in which the integrals and their {\em labels}
(the indices $ i , j, k, \ell $) are stored in the buffer (and
therefore in the final file) depends on a number of tactical
considerations.
\subsection{\sf Storage Formats}
At the moment, there are {\em four} different storage formats for two
electron integrals. In the  discussion below 
the {\bf charge cloud} notation will be used for
the electron repulsion integrals over {\em real} basis functions:
\[
(i j , k \ell ) =
 < \phi_i \phi_k | \phi_j \phi_{\ell} > = 
\int { dV_1 \int { dV_2 \phi_i (\vec{r_1})\phi_j (\vec{r_1})
\left ( \frac{1}{r_{12}} \right )
\phi_k (\vec{r_2})\phi_{\ell} (\vec{r_2}) } }
\]
\begin{description}
\item[Format 0] each integral value $(ij,k \ell )$ 
is stored together with its four
indices $ i , j , k , \ell $.
One of these Format 0 integrals can be further classified 
according to whether or not any
indices are coincident. that is, the integral (43,21) is stored
differently than say (53,22). Integrals having no coincidences are
classified as {\bf type 1} integrals; those involving coincidences are
termed {\bf type 2} integrals.
It turns out to be advantageous in the SCF if type 1 and type 2
integrals are separated. In order to achieve this separation, type 1
integrals are loaded into the buffer starting at the beginning and
type 2 integrals starting at the end of the buffer. When the two types
meet, the buffer is full, and then written out.
each label-integral combination that is inserted into the buffer
has the storage requirements of
one (long) integer and one double-precision real;
that is 12 bytes long (one byte = 8 bits) on many systems. 
The label portion occupies the
integer portion, and the remaining storage contains $(ij,k \ell )$ stored in
full double precision. 
The storage of the {\em four} indices of
the integral in the space of {\em one}
long integer is a device to save file space;
clearly the {\em values} of the indices are {\em small integers},
typically not greater than 100. 
In addition to being in different parts of the
buffer, type 1 and type 2 integrals have different label construction.
A type 1 label consists of four areas containing $ i,j,k, \ell $. 
A type
2 label consists of three areas containing up to three unique
indices, and a smaller code  containing an index indentifying the
type of coincidences involved.
\item[Format 1] It is possible to achieve substantial savings in the
steps that process the two-electron integrals if the integrals are
pre-processed suitably in the integral generation Links. 
This technique was
originally suggested by R.  Raffenetti {\em (Chem. Phys. Lett.(1973), {\bf 20},
p335)}
who advocates sorting the integrals to achieve time savings. Specifically,
if 
\begin{equation}
(i j ,k \ell ) = ( i j , k \ell )
- 0.25 [ (i \ell , j k ) + (i k , j \ell ) ]
\label{raff1}
\end{equation}
is computed and stored,
the SCF processing time can be reduced by about a factor of three for
standard closed shell computations.

Using this storage mode, the buffer is divided into two partitions.
The first partition contains all the labels, and the second partition
contains the integrals. In this case it is not necessary to store all four
indices $i , j , k , \ell $, but only the {\em linearized} 
indices $(ij)$ and $(k \ell )$,
\[
(ij) = (i(i-1))/2 + j
\]
\[
(k \ell ) = (k(k-1))/2 + \ell
\]
thus a label consists of two short integer quantities containing $(ij)$ and
$(k \ell )$. The integral is again stored as a full double precision value.
\item[Format 2] Two other quantities related to (1) can de identified which
are necessary for open shell calculations and complex SCF calculations:
\begin{eqnarray}
(i j | + | k \ell ) = (i \ell , j k )  + (i k , j \ell ) \\
\label{raff2}
( i j | - | k \ell ) = ( i \ell , j k )  - ( i k , j \ell )
\label{raff3}
\end{eqnarray}
Format 2 is identical to format 1 except that {\em two} floating point
numbers are stored for each label: integrals \ref{raff2} and \ref{raff3}.
\item[Format 3] This format is identical to format 2 except now we store
all three combinations.
\end{description} 
\subsection{\sf Buffer construction}
As the integrals are computed, they are loaded into a buffer
(working array in memory) according to one of the above prescriptions.
When the buffer is filled, a control word characterizing the buffer is
appended, and the buffer is written out. The {\em buffer control word}
contains a code indicating whether or not the current buffer is the
last buffer. It also contains the count of the number of integrals
within the buffer. Note that for format 1 buffers, two counts are
required, one for each type of integral. This control word is
currently placed at the beginning of the buffer.

The size of a buffer is currently set to 4760 double precision
words, which is 19040 bytes. This is entirely historical; 
it is the size of a track on a now-obselete IBM
disk pack. This size can be changed by modifiying the parameters located
in {\tt SUBROUTINE SET2E} (L301), but this must only be done with
extreme caution as the size of this buffer appears {\em explicitly}
in many places in the system.
\subsection{\sf I/O Considerations}
The necessary routines to read and write the integral buffers are
available as entry points in the {\tt SUBROUTINE INTEGI}.
The relevant {\tt ENTRY} pointa are:
\begin{description}
\item[\tt IREAD] reads a buffer.
\item[\tt IWRITE] writes a buffer.
\item[\tt IWAIT] waits for the previous I/O request. \\
{\bf Not implemented in {\tt gnu80} - see NTRAN manual page}
\item[\tt IWIND] rewinds the integral file.
\end{description}
\subsection{\sf Implementation Considerations}
FORTRAN language routines are available to pack and unpack the
three different label types (format 0, types 1 and 2; formats 1,2 and
3).   these routines are:
\begin{description}
\item[\tt PACK1, UNPCK1] format 0, type 1
\item[\tt PACK2, UNPCK2] format 0, type 2
\item[\tt PACK3, UNPCK3] formats 1,2,3
\end{description}
It is not necessary to have a detailed description of these
routines, simply that each {\em pair} is complementary.
\section{\sf Parsing the Command Record}
In order to be able to make significant changes to {\tt gnu80} (adding new
links and the possibility of new Routes) it is necessary to
understand how the Route is generated from the command record.
The command record must be {\em parsed} for the meaning of the
symbols it contains, checked for errors and meaningless symbols
and finally the correct command translated into a valid Route.

These tasks are performed by the {\tt INTEGER FUNCTION QPARSE} and its
associated data structure a {\em Parse Table}. The information
in the following sections, together with a study of the use of
{\tt QPARSE} in {\tt gnu80}, should enable the user to master the
parsing of the command record.
\subsection{\sf {\tt QPARSE} use}
{\tt QPARSE} is a table-driven line parser. It is called with a 
{\em string of characters} to
be parsed, a parse table, and a {\em Result Vector.} 
The input string is just
a string of characters which, in line with the design
of {\tt gnu80}, is contained in an INTEGER array.  
The parse table tells the FUNCTION which sub-strings are meaningful
in the input string (a number, a certain keyword,
etc.), and what to do if a specified meaningful sub-string 
is found in the input string.

The {\tt RESULT} Vector contains the output from {\tt QPARSE}. 
The specification of {\tt QPARSE} is:
\begin{verbatim}
      INTEGER FUNCTION QPARSE(RESULT,TABLE,LINE,LENGTH)
      INTEGER RESULT(1), TABLE(1), LINE(1), LENGTH
\end{verbatim}
\begin{description}
\item[{\tt LINE}] contains the (ASCII) string to be parsed
stored four characters to a (default) integer.
\item[{\tt TABLE}] is a DATA structure containing the information necessary to
parse the string in {\tt LINE}
This structure is discussed in detail below.
\item[{\tt RESULT}] is an INTEGER array in which the results of the parse
are stored. The description of the {\tt TABLE} structure
gives the meaning of the {\tt RESULT} array.
\item[{\tt LENGTH}] The number of {\em characters} in the string stored
in {\tt LINE}.
\item[{\tt QPARSE}] The {\tt INTEGER} value returned by
{\tt QPARSE} gives the status of the
parse. The possibilities are:
\begin{description}
\item[{\tt 0}] Success; a transition has occured to {\tt EXI}
\item[{\tt -1}]  Failure; a transition has occured to {\tt FAI}. This
indicates some syntax error in the input string.
\item[{\tt -2}]    Failure: an ambigous keyword was detected in the
input string.
\item[{\tt -3}]  Error; an error was detected in the parse table.
\item[{\tt 1}]      Return; the parse is not yet completed, but
control has returned to the caller because of a
parse-table request.
\end{description}
\end{description}
Before any calls to {\tt QPARSE} are made,
the routine must be initialized by a call to
{\tt QPINIT} which sets certain options to {\tt QPARSE}.
\begin{verbatim}
      SUBROUTINE QPINIT(TABLE,BLNKS,CAPS,ABVRS)
      INTEGER TABLE(1), BLNKS, CAPS, ABVRS
\end{verbatim}
\begin{description}
\item[{\tt TABLE}] the parse table used as input to {\tt QPARSE}. The
remaining arguments set options in the parser. 
\item[{\tt BLNKS}]   By default, 
any number of (contiguous) blanks and tabs in the input string are treated
as invisible delimiters.
A non-zero value for {\tt BLNKS} means that
blanks will be seen by {\tt QPARSE}.
\item[{\tt CAPS}]     By default, the difference between upper and lower case
letters is ignored. A non-zero value of {\tt CAPS} indicates that
only exact matches are acceptable. 
\item[{\tt ABRVS}] By default, any unambiguous abbreviation is allowed for
a keyword. A non-zero value of {\tt ABRVS} makes abbreviations
non-acceptable.
\end{description}
The following material describes how to construct a
parse table with some examples.
\section{\sf The {\tt QPARSE} Table}
The {\tt QPARSE} table, which descibes how the input record is to be
parsed, can be built with FORTRAN {\tt DATA} statements. 

The table consists
of one or more {\em states}, and the general structure of the table is
illustrated below:
\newpage
\begin{center}
% \fbox{
% \parbox{3in}{
\begin{verbatim}
<name-of-state>             (1 default integer)
<transition definition>     (variable length)
<transition definition>         "       "
          "
          "
          "
<end-of-state>              (1 default integer)
<name-of-state>             (1 word)
<transition definition>
          "
          "
          "
<end-of-state>
<end-of-table>              (1 default integer)
\end{verbatim}
% }
% }
\end{center}
Thus, the table consists of one or more states, and each state
consists of one or more {\em transition definitions}. Generally, the states
provide the overall control structure for the parse, and the transition
definitions provide the details of what to look for in the input record,
and what to do if it's found.

The $<$name-of-state$>$ field is just a string of up to four
characters which labels the state. The parser has three pre-defined
state names which should not be used as $<$name-of-state$>$ fields in the
table. 
These are {\tt RET}, {\tt EXI} and {\tt FAI}. The use and importance of
these special state names are descibed below in the detailed
description of the transition definition. The $<$name-of-state$>$ field may
be left zero in some cases, but one default integer must always be
allocated in the table.

The $<$transition definition$>$ field is of variable length and is
discussed in detail below. Generally, a transition definition tells the
parser what kind of object to look for in the input record (keyword,
character, integer, etc.), and what to do if it's found. If the object
specified by the transition definition matches the next character(s) in
the input record, then the character(s) from the input record are accepted,
and a state transition occurs. This transition may be to a new state,
or just back to the top of the transition definition. Other subfields
of the transition definition can specify one of a set of simple
operations which can be performed during the transition:
\begin{itemize}
\item Store the object accepted from the input record into a
specified storage location.
\item Add a given value into a specified storage location.
\end{itemize}
The $<$end-of-state$>$ mark is just aa integer with a particular value
({\tt EOS}) which terminates the state. If none of the transition
definitions in the current state succeeds, then this mark will be
encountered and a transistion will occur to the special state {\tt FAI} and
the parse fails. In this case, a failure status will be returned by
{\tt QPARSE}.

The $<$end-of-table$>$ mark is just a $<$name-of-state$>$ field containing
the value {\t END}.
\subsection{\sf Transition Definitions}
A {\em transition definition} consists of a number of subfields, one of
which is of variable length:

$<$alphabet token$>$, $<$destination$>$,$<$index$>$,$<$value$>$

Each of these subfields is discussed individually below.
\begin{description}
\item[$<$token$>$] This  field describes what to look for in the input record. 
If
this token matches the next data in the input record, then the data in
the record is {\em accepted}, and the transition succeeds. 
For instance, one 
can ask:
\begin{quote}
``if the next characters in the record form a decimal integer,
then accept them and make the transition.'' 
\end{quote}
Characters which are
accepted are removed from the front of the input record, and subsequent
transition definitions will try to match whatever characters come after
these. If the transition succeeds, then the rest of the transition
definition is used to determine the details of what actions are to be
taken. If there is no match, then the transition fails, and the next
transition definition in the current state is checked against the same
characters. If no transition definitions remain, then a transition to
the state {\tt FAI} occurs, and the parse fails. The various tokens, some
of which are longer than one integer, are detailed below in the
section on the {\tt QPARSE} alphabet.
\item[$<$destination$>$] This field is a string of characters which names the
state to which the transition is to be made. If this field is zero,
then a transition is made to the state immediately following the
current state. Otherwise, this string should match either one of the
specified state names, or one of the $<$name-of-state$>$ fields in the
table. The special states, and the effect of a transition to each is
detailed below:
\begin{description}
\item[{\tt EXI}]        Causes the parser to halt, and to return an 
zero
status (return value of {\tt QPARSE}). 
A transition to {\tt EXI} indicates succesfull
completion of the parse.
\item[{\tt FAI}]        causes the parser to halt, and return a failure
status. A transition to {\tt FAI} indicates a syntax
error in the input record.
\item[{\tt RET}]        causes a transition to the state immediately
following the current one in the table.
However, control is returned to the calling routine
before the first transition definition in this new
state is examined. This is useful when the calling
routine needs to perform some other action before
the parse can continue.
\end{description}
\item[ $<$index$>$ and $<$value$>$] These fields are used to request some simple
operations which can be performed during the transition. 
If both of
these values are non-zero, then  $<$value$>$  is added into
{\tt RESULT($<$index$>$)}. 
{\tt RESULT} is one of the calling arguments to the parser.
If only the $<$index$>$ field is non-zero, then the object accepted from
the input record (character, integer, keyword, etc.) is stored into
{\tt RESULT($<$index$>$)}. If the $<$index$>$ field is zero, then nothing is done
during the transition.
\end{description}
\subsection{\sf {\tt QPARSE} Alphabet}
\begin{enumerate}
\item  Tokens which match single characters. \\
If it is requested that
this token be stored into {\tt RESULT} (a zero value for $<$value$>$), then this
character is justified in the indicated word as {\tt A1}.
\begin{description}
\item[{\tt NUM}]    matches any numeric character.
\item[{\tt ALP}]    matches any alphabetic character.
\item[{\tt ALN}]    matches any alphanumeric character.
\item[{\tt CHR}]    matches any character.
\end{description}
\item Tokens which match numbers. If it is requested that one of these be
stored in {\tt RESULT}, the corresponding numeric value is stored there.
Note the difference, then, between the tokens {\tt NUM} and {\tt D10} 
(below).
Each of these matches one numeric character in the input record, but
there is a difference if the object accepted is to be stored into
{\tt RESULT}. {\tt NUM} causes the {\em character} to be stored there, while 
{\tt D10}
causes the corresponding integer value to be stored. The following
tokens are recognised:
\begin{description}
\item[{\tt D10}]    matches a base 10 digit.
\item[{\tt D16}]    matches a hexadecimal digit.
\item[{\tt D8}]     matches an octal digit.
\item[{\tt D2}]     matches a binary digit.
\item[{\tt I10}]    matches a decimal integer. this must be terminated
in the input record by a non-alphanumeric character (or
by the end of the input record).
\item[{\tt I16}]    matches a hexadecimal integer.
\item[{\tt D8}]     matches an octal integer.
\item[{\tt I2}]     matches a binary integer.
\item[{\tt FP}]     matches a floating point number.
\item[{\tt DP}]     matches a double precision floating point number.
the only difference between this and {\tt FP} is that this
takes two locations in {\tt RESULT}.
(starting with {\tt RESULT($<$index$>$)}.
\end{description}
\item  Tokens which match strings. If one of these is to be stored
into {\tt RESULT}, then a variable number of words in {\tt RESULT} 
will be used,
depending unpon the length of the string. The integer actually indicated
by $<$index$>$ will contain a count of characters in the string, and
subsequent words will contain the ASCII string. The following tokens
are recognised:
\begin{description}
\item[{\tt N,$<$keyword$>$}] This token matches a keyword. 
{\tt N} is a positive
integer which indicates the number of characters in
the keyword which follows. For instance, the token
describing the keyword ``HELLO''  takes three integers;
\begin{center}
5, {\tt 'HELL','O'}
\end{center}
By default, any abbreviation is accepted for a
keyword, as long as it is unambiguous. A keyword is
defined as an alphanumeric string terminated by a
non-alphanumeric character. Thus, if the characters
'HELLOAB' were at the front of the input record,  the
above token ('HELLO') would not match, since the
string 'HELLO' in the input record is not terminated by
a {\em non-alphanumeric} character.
\item[{\tt -N,$<$string$>$}]    This variable-length token matches a specific
string of characters.  {\tt -N} means that the
character(s) to be matched follow in the next
{\em integer(s)}. For instance, the token:
\begin{center}
-5,'HELL','O'
\end{center}
matches the string 'HELLO'. note the difference
between the token for the string 'HELLO' and that for
the keyword 'HELLO'. If the input record contains the
characters 'HELLOAB', the string 'HELLO'
(-5,'HELL','O') will match. The keyword 'HELLO'
(5,'HELL','O') will not match, however, since it is
not terminated by a non-alphanumeric character in the
input record.
\item[{\tt WRD}]  This token matches any alphanumeric string
(terminated by a non-alphanumeric character).
\item[{\tt STR,N,$<$delims$>$}] Matches a user-defined string. This is similar
to {\tt WRD}, except that the characters which delimit
the desired string are supplied in the token. {\tt N} is
the number of such delimiters, and the delimiting
characters are supplied in the subsequent words.
\end{description}
\item Tokens which remove no characters from the input string.
The following are recognised:
\begin{description}
\item[{\tt NUL}]     Always matches. This results in no characters being
removed from the front of the input record, but
the supplied transition occurs. It is useful as a
``go to'' -type command.
\item[{\tt EOL}]         Matches end-of-line. 
If there are no more characters
in the input record, then this token matches.
\end{description}
\end{enumerate}
\section{\sf Character Manipulation in {\tt gnu80}}
The design of the character manipulation system in {\tt gnu80}
is necessarily based on that of the GAUSSIAN series and it
{\em predates} the introduction of the {\tt CHARACTER} data type in
FORTRAN; all character strings are therefore stored and manipulated
in other data types, principally {\tt INTEGER}.

This has two unfortunate effects from the point of view of
FORTRAN 77 portability:
\begin{enumerate}
\item It renders the system difficult to change to make use of
the {\tt CHARACTER} data type since many of the data structures
of type {\tt INTEGER} contain actual integer values as well
as character strings; that is, there is not the possibility of
simply changing the {\em type} of the variables used to store
character strings.
\item It is a potential source of disaster, since the storage of
character strings in non-{\tt CHARACTER} data type is likely to
be discontinued in FORTRAN. Many current compilers do not allow this
extension to the ANSI standard and all will flag it as a warning.
\end{enumerate}
The use of {\tt 'A'} as a character constant pre-dates the introduction
of the {\tt CHARACTER} data type so that {\tt gnu80} contains character strings
stored in {\tt INTEGER} data types {\em and} genuine FORTRAN 77
character constants as well as the occasional
Hollerith string. 

The introduction of the {\tt CHARACTER}
data type {\em together with an implicit length} causes a 
complication in FORTRAN {\tt SUBROUTINE} argument transmission, since
somehow, the {\em length} of a character string must be passed
through an interface. Since all FORTRAN argument passing is done
{\em by address} this means that an additional argument (hidden from
the user) must be passed if a {\tt SUBROUTINE} has an argument of
type {\tt CHARACTER}.
Specifically, if a {\tt SUBROUTINE} has an argument {\tt I}, then the
following combination of code is {\em not allowed}:
\newpage
\begin{verbatim}
      SUBROUTINE NAME(I)
      INTEGER I
      .
      .
      RETURN
      END
      
      PROGRAM MAIN
      INTEGER K
      CHARACTER*4 J
      .
      .
      CALL NAME(K)
      .
      CALL NAME(J)
      .
      CALL NAME('ABCD')
      .
      END
\end{verbatim}
The compiler may not allow it or it may crash on execution
since the second and third {\tt CALL}s actually generate {\em two}
arguments in the passage to {\tt NAME}; the address of the string and its
length. It is therefore necessary to have {\em two}
routines to perform some character string manipulations; using the 
above example the routines {\tt NAMEC} and {\tt NAMEI} are required to
make the following code acceptable.
\newpage
\begin{verbatim}
      INTEGER K
      CHARACTER*4 J
      DATA K/'WXYZ'/
      DATA J/'ABCD'/
      .
      .
      .
      CALL NAMEI(K)
      .
      .
      CALL NAMEC(J)
      .
      .
      END
      
      SUBROUTINE NAMEC(I)
      CHARACTER*(*) I
      .
      .
      RETURN
      END
      
      SUBROUTINE NAMEI(I)
      INTEGER I
      .
      .
      RETURN
      END
\end{verbatim}
and the routine {\tt NAMEC} {\em must} be used in statements like \\
\begin{center}
{\tt CALL NAMEC('FGHJ')}
\end{center}
i.e. with character constant arguments.

This compromise has been adopted in {\tt gnu80} and all the character
manipulation routines are prime candidates for systematic replacement
by ANSI FORTRAN 77 equivalents. A very brief specification of the 
routines is given below.
However, the use of {\tt INTEGER}s to store character strings has the
effect of making the routines potentially compiler-dependent in the
sense that a charcter input to an {\tt INTEGER} variable by
reading in A1 format or by a {\tt DATA } statement may
be stored at {\em either end} of the storage area 
assigned to the {\tt INTEGER} since {\tt INTEGER} type occupies more
storage than {\tt CHARACTER*1} type.
There are only two rational possibilities, storage at the most or
least significant end of the {\tt INTEGER} and both are used by
different compilers. In {\tt gnu80} this potential non-portability
has been concentrated into the {\tt FUNCTION IORD}
which {\em tests} which type of storage has been used before
manipulating the characters (assuming that the
characters are stored as ASCII codes) see \ref{iord}. 
The only remaining and highly unlikely
source of disaster is if a compiler uses a different allocation
for the result of reading an {\tt INTEGER} in
A1 format from the allocation generated by a statement like \\
\begin{verbatim}
      DATA INT /'A'/
\end{verbatim} 
\section{\sf Main Character Manipulation Routines}
Since the specification of these small {\tt SUBROUTINES} and
{\tt FUNCTIONS} is rather brief, only a concise description of each
is given; that is, the full manual page format is not used.

The three central string manipulation routines are {\tt GETCHR}, {\tt PUTCHR}
{\tt LORD} and {\tt IORD}. 

The two arguments to the {\tt INTEGER  FUNCTION  GETCHR} are a string
and a cursor. The value of the cursor is incremented by one, then the
``cursor-th''  character in the string, padded with blanks, 
is returned as
the {\tt INTEGER} value of the function. 
This returned character is justified in the
word as A1 in {\tt FORTRAN}.
For instance, the {\tt FORTRAN} statements:
\begin{verbatim}
      INTEGER GETCHR
      I = 12
      J = GETCHR('A CHARACTER STRING, I)
\end{verbatim}
results in {\tt J} being assigned the value of {\tt 'S'} in the sense
defined above; the actual value of {\tt J} as an {\tt INTEGER} type
depends on the machine/compiler but will be consistent with other
of the routines described below.

The following statement is not allowed in FORTRAN 77:
\begin{verbatim}
      IF ( J .EQ. 'S') .....
\end{verbatim}
Therefore all logical comparisons are made by the use of {\tt DATA}
statements and {\tt INTEGER} comparisons:
\begin{verbatim}
      DATA CHS/'S'/
      IF (J .EQ. CHS) ...
\end{verbatim}
or, (in general) by the use of the {\tt FUNCTION} {\tt IORD}:
\begin{verbatim}
      IF (J .EQ .IORD('S'))  ...
\end{verbatim}
Both the {\tt DATA} statement and the {\tt FUNCTION IORD}
justify the character
as in A1 format.
\subsubsection{\sf INTEGER FUNCTION GETCHR}
\begin{verbatim}
      INTEGER FUNCTION GETCHR(STRING, CURSOR)
      INTEGER STRING(1), CURSOR
\end{verbatim}
This integer function increments  {\tt CURSOR} by one, 
and returns as its value
the character in {\tt STRING} pointed to by the 
new value of {\tt CURSOR}. The returned value will
be justified in the {\tt INTEGER} as if it had been read in A1 format, 
and the
rest of the character positions will be padded with blanks (ASCII 32).  
\subsubsection{\sf SUBROUTINE PUTCHR}
\begin{verbatim}
      SUBROUTINE PUTCHR(CHR,STRING,CURSOR)}
      INTEGER STRING(1), CURSOR
      CHARACTER*1 CHR
\end{verbatim}
This routine first increments {\tt CURSOR} by one, 
then puts the character  in
{\tt CHR} into {\tt STRING} at the location pointed by  {\tt CURSOR}. \\
{\bf This routine is the one to use when characters which are stored in
variables of type} {\tt CHARACTER} {\bf are to be added to a }
{\tt STRING}.
\subsubsection{\sf SUBROUTINE PUTICR}
\begin{verbatim}
      SUBROUTINE PUTICR(CHR,STRING,CURSOR)}
      INTEGER STRING(1), CHR, CURSOR
\end{verbatim}
This routine first increments {\tt CURSOR} by one, 
then puts the character  in
{\tt CHR} into {\tt STRING} at the location pointed by  {\tt CURSOR}.
{\bf This routine is the one to use when characters which are stored in
variables of type} {\tt INTEGER} {\bf are to be added to a }
{\tt STRING}. \\

To illustrate the difference between {\tt PUTCHR} and {\tt PUTICR},
the following pieces of code have the same effect on {\tt STRING}:
\begin{verbatim}
      CURSOR=3
      CALL PUTCHR('A', STRING, CURSOR)
\end{verbatim}
and
\begin{verbatim}
      INTEGER IA
      DATA IA/'A'/
      CURSOR = 3
      CALL PUTICR(IA, STRING, CURSOR)
\end{verbatim}
\subsubsection{\sf INTEGER FUNCTION IORD}
\label{iord}
\begin{verbatim}
      INTEGER FUNCTION IORD(CHR)
      CHARACTER*(*) CHR
\end{verbatim}
This function returns the 
(machine/compiler dependent) {\tt INTEGER} value of the 
character string {\tt CHR} (up to four
characters). 
It should be called by {\tt IORD('A')} or by
{\tt IORD('ABCD')} i.e. a {\tt CHARACTER} constant or
variable of length up to 4. 
It will return the same value as a comparable {\tt DATA}
statement would.
As supplied, the function uses a simple test to discover how
the machine/compiler stores characters in a variable of type
{\tt INTEGER} before performing the manipulation. The test is
simply whether or not the {\tt INTEGER} variables {\tt IA} and
{\tt IB} generated by
\begin{verbatim}
      INTEGER IA, IB
      DATA IA, IB/'A','B'/
\end{verbatim}
differ by one or not.  The assumption is that, if they differ by one,
then the character is stored at the {\em least} significant end of
the {\tt INTEGER} if not, then the character is stored at the {\em most}
significant end of the integer.
Inspection of the actual code shows that this test simply chooses
an integer offset which is 1 or 4. If it is {\em known} which mode
of storage is used in a particular machine then this constant may
be unilaterally set to 1 or 4 to avoid these repeated tests. This is
{\em not} reccommended since the function is a very minor consumer
of computer time!
\subsubsection{\sf INTEGER FUNCTION LORD}
\begin{verbatim}
      INTEGER FUNCTION LORD(CHR)
      CHARACTER*1 CHR
\end{verbatim}
This routine returns the entry number of the {\tt CHARACTER} variable
{\tt CHR} in the
ASCII character table. It is implemented by a call to the FORTRAN 77
standard function {\tt ICHAR}.
\subsubsection{\sf INTEGER FUNCTION ILORD}
\begin{verbatim}
      INTEGER FUNCTION ILORD(CHR)
      INTEGER CHR
\end{verbatim}
This routine returns the entry number of the first character 
contained in the {\tt INTEGER} variable {\tt CHR} in the
ASCII character table. It is the same as {\tt LORD} for an
{\tt INTEGER} argument. The reasons for its existence are the same as
for the {\tt PUTCHR/PUTICR} pair.  
\subsubsection{\sf LOGICAL FUNCTION IFALPH}
\begin{verbatim}
      LOGICAL FUNCTION IFALPH(CHR)
      INTEGER CHR
\end{verbatim}
This logical function returns {\tt .TRUE.} if the 
'first' character in the {\tt INTEGER}
{\tt CHR} is an alphabetic character, {\tt .FALSE.} if otherwise.
\subsubsection{\sf INTEGER FUNCTION CROP}
\begin{verbatim}
      INTEGER FUNCTION CROP(CHR)
      INTEGER CHR
\end{verbatim}
This function returns as its value the character in {\tt CHR} with all
character locations except the first replaced by blanks.
\subsubsection{\sf INTEGER FUNCTION INTCHR}
\begin{verbatim}
      INTEGER FUNCTION INTCHR(CHR,BASE)
      INTEGER CHR, BASE
\end{verbatim}
This function returns the numeric value of the digit which is in
the 'first' character in the {\tt INTEGER} {\tt CHR}. 
If this character is not a
digit in base {\tt BASE}, then a value of -1 is returned.
(thus 0..9, A..F returns 0..15 if {\tt BASE}=16).
\subsubsection{\sf LOGICAL FUNCTION STREQ}
\begin{verbatim}
      LOGICAL FUNCTION STREQ(STR1,STR2,LEN)
      INTEGER STR1(1), STR2(1), LEN
\end{verbatim}
This function returns {\tt .TRUE.} if the two strings have {\tt LEN} equal
characters, or {\tt .FALSE.} otherwise.
\subsubsection{\sf SUBROUTINE STROUT}
\begin{verbatim}
      SUBROUTINE STROUT(IOUT,STR,LEN,CRLF)
      INTEGER IOUT, STR(1), LEN, CRLF
\end{verbatim}
This routine just outputs a character string to FORTRAN unit {\tt IOUT}.
The characters to be output are in {\tt STR}, and there are {\tt LEN} of these
characters.  {\tt CRLF} indicates whether a ``newline'' 
is desired at the end
of the string (0 means no, 1 means yes).  {\tt CRLF=-1} 
indicates that the current
{\tt STR} should be printed on the same line as the previous one. Note that
the {\tt CRLF} specifications are only compatible with other {\tt STROUT} 
calls,
not with the standard FORMAT I/O calls.
\subsubsection{\sf SUBROUTINE LOCSTR}
\begin{verbatim}
      SUBROUTINE LOCSTR(SUBSTR,LENSUB,STRING,LENSTR,CURSOR)
      INTEGER SUBSTR(1), LENSUB, STRING(1), LENSTR, CURSOR
\end{verbatim}
This routine searches through {\tt STRING} for the {\tt SUBSTR}. 
The search starts
at the current location of the {\tt CURSOR} in {\tt STRING}. 
{\tt LENSUB} is the length
of the substring, and {\tt LENSTR} is the length of the string to be
searched. The value of {\tt CURSOR} is updated so that  {\tt GETCHR} 
will return
the first character of the substring. If no match is found, {\tt CURSOR} is
returned -1.
\subsubsection{\sf SUBROUTINE APPFP}
\begin{verbatim}
      SUBROUTINE APPFP(X,N,BB,NBB)
      DOUBLE PRECISION X, BB(1)
      INTEGER N, NBB
\end{verbatim}
This routine puts the characters representing the {\tt DOUBLE PRECISION}
value {\tt X} into the buffer {\tt BB}, updating the cursor {\tt NBB} 
as it does. The
argument {\tt N} is the number of desired figures after the decimal point
(maximum 12).
\subsubsection{\sf SUBROUTINE APPFFD}
\begin{verbatim}
      SUBROUTINE APPFFD(X,NDECIM,BB,NBB)
      DOUBLE PRECISION X, BB(1)
\end{verbatim}
Same routine as {\tt APPFP} but now the representation is in FORTRAN
{\tt D-FORMAT}.
\subsubsection{\sf INTEGER FUNCTION DELTYP}
\begin{verbatim}
      INTEGER FUNCTION DELTYP(CHR)
      INTEGER CHR
\end{verbatim}
This function checks to see what kind of delimiter the character in {\tt CHR}
is. possible values of the function are:
\begin{description}
\item[0] the character is not a delimiter.
\item[1] the character is a word delimiter.
\item[2] the character is a statement delimiter.
\item[4] the character is a record delimiter.
\end{description}
\subsubsection{\sf INTEGER FUNCTION NCHRPW}
\begin{verbatim}
      INTEGER FUNCTION NCHRPW(IDUMMY)
      INTEGER IDUMMY
\end{verbatim}
This function returns the number of characters which can be represented
in a single precision {\tt REAL} or an {\tt INTEGER} (4 in most cases).


